{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Hyperparameter Tuning - Titanic Survival\n",
    "\n",
    "**Goal:** Optimize the best performing model(s) from the benchmark to squeeze out maximum accuracy.\n",
    "\n",
    "**Selected Methods:**\n",
    "1. **Random Forest Tuning** (Grid Search)\n",
    "2. **XGBoost Tuning** (Randomized Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T00:09:27.557056Z",
     "iopub.status.busy": "2025-12-24T00:09:27.557056Z",
     "iopub.status.idle": "2025-12-24T00:09:29.195855Z",
     "shell.execute_reply": "2025-12-24T00:09:29.193065Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Pipeline Setup\n",
    "\n",
    "Re-establishing the preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T00:09:29.206368Z",
     "iopub.status.busy": "2025-12-24T00:09:29.204096Z",
     "iopub.status.idle": "2025-12-24T00:09:29.257199Z",
     "shell.execute_reply": "2025-12-24T00:09:29.254060Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/train.csv')\n",
    "df['Title'] = df['Name'].apply(lambda x: x.split(',')[1].split('.')[0].strip())\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n",
    "\n",
    "X = df[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Title', 'FamilySize', 'IsAlone']]\n",
    "y = df['Survived']\n",
    "\n",
    "numeric_features = ['Age', 'Fare', 'FamilySize']\n",
    "categorical_features = ['Pclass', 'Sex', 'Embarked', 'Title', 'IsAlone']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), numeric_features),\n",
    "        ('cat', Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Random Forest Grid Search\n",
    "\n",
    "Exhaustive search over specified parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T00:09:29.265623Z",
     "iopub.status.busy": "2025-12-24T00:09:29.264081Z",
     "iopub.status.idle": "2025-12-24T00:10:33.243833Z",
     "shell.execute_reply": "2025-12-24T00:10:33.241263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Params: {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 100}\n",
      "Best RF Score: 0.8361308141359614\n"
     ]
    }
   ],
   "source": [
    "pipeline_rf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('classifier', RandomForestClassifier(random_state=42))])\n",
    "\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 5, 10, 20],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "grid_rf = GridSearchCV(pipeline_rf, param_grid_rf, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_rf.fit(X, y)\n",
    "\n",
    "print(\"Best RF Params:\", grid_rf.best_params_)\n",
    "print(\"Best RF Score:\", grid_rf.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. XGBoost Randomized Search\n",
    "\n",
    "Randomized search allows testing a wider range of values efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T00:10:33.248717Z",
     "iopub.status.busy": "2025-12-24T00:10:33.248717Z",
     "iopub.status.idle": "2025-12-24T00:10:36.640277Z",
     "shell.execute_reply": "2025-12-24T00:10:36.638305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGB Params: {'classifier__subsample': 0.8, 'classifier__n_estimators': 100, 'classifier__max_depth': 7, 'classifier__learning_rate': 0.05, 'classifier__colsample_bytree': 0.8}\n",
      "Best XGB Score: 0.843977151465696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravikiran Bhonagiri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:199: UserWarning: [18:10:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:790: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "pipeline_xgb = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                               ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'))])\n",
    "\n",
    "param_dist_xgb = {\n",
    "    'classifier__n_estimators': [100, 300, 500],\n",
    "    'classifier__learning_rate': [0.01, 0.05, 0.1, 0.3],\n",
    "    'classifier__max_depth': [3, 5, 7, 9],\n",
    "    'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.8, 1.0]\n",
    "}\n",
    "\n",
    "rand_xgb = RandomizedSearchCV(pipeline_xgb, param_dist_xgb, n_iter=20, cv=5, verbose=1, n_jobs=-1, random_state=42)\n",
    "rand_xgb.fit(X, y)\n",
    "\n",
    "print(\"Best XGB Params:\", rand_xgb.best_params_)\n",
    "print(\"Best XGB Score:\", rand_xgb.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Final Evaluation\n",
    "\n",
    "Comparing the tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-24T00:10:36.644613Z",
     "iopub.status.busy": "2025-12-24T00:10:36.644613Z",
     "iopub.status.idle": "2025-12-24T00:10:36.690264Z",
     "shell.execute_reply": "2025-12-24T00:10:36.687920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÖ Winner: XGBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93       549\n",
      "           1       0.92      0.83      0.88       342\n",
      "\n",
      "    accuracy                           0.91       891\n",
      "   macro avg       0.91      0.89      0.90       891\n",
      "weighted avg       0.91      0.91      0.91       891\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if grid_rf.best_score_ > rand_xgb.best_score_:\n",
    "    print(\"üèÖ Winner: Random Forest\")\n",
    "    best_model = grid_rf.best_estimator_\n",
    "else:\n",
    "    print(\"üèÖ Winner: XGBoost\")\n",
    "    best_model = rand_xgb.best_estimator_\n",
    "\n",
    "# Final metrics on entire training set (or hold-out if we had one)\n",
    "y_pred = best_model.predict(X)\n",
    "print(classification_report(y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
